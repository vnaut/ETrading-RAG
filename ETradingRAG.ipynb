{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Wzss-UVRYK"
      },
      "source": [
        "Installing packages that will be utilized in RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UQQGlU8xb3R-",
        "outputId": "d4229d13-be02-4f51-c6a4-4e7d513927a4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community langchain-core langchain-openai\n",
        "!pip install chromadb\n",
        "!pip install tiktoken google-search-results\n",
        "!pip install pydantic\n",
        "!pip install typing-inspect typing_extensions\n",
        "!pip install loguru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-JqR2AAV0h9"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oCw2Ch2cS_d"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from langchain_community.document_loaders.directory import DirectoryLoader\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.chroma import Chroma\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from loguru import logger\n",
        "\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLuuhskIWAMa"
      },
      "source": [
        "Configure OS environment to utilize OpenAI and LangChain APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAXIHAuvcZue"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = # Insert OpenAI API key here\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = # Insert LangChain API key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDjvyvfKeJz8",
        "outputId": "bead205f-d411-4a35-e4ae-015838932265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-B3XHF1eoyk"
      },
      "outputs": [],
      "source": [
        "directory_path = # Enter path to data folder stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYNLVU4Ze7GV"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22YfzjeGWxHr"
      },
      "source": [
        "Load data into LangChain using Directory Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy1-d_sYoFsv",
        "outputId": "7501be4c-df5d-47c9-eba2-e546a64443fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:00<00:00, 167.78it/s]\n"
          ]
        }
      ],
      "source": [
        "loader1 = DirectoryLoader(directory_path, glob = \"**/*.txt\", show_progress = True, loader_cls = TextLoader)\n",
        "txt_docs = loader1.load_and_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W78U4P3gVCYq"
      },
      "source": [
        "Create embeddings and generate local ChromaDB vector database using the documents provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbfFzg2xfder"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "embeddings = OpenAIEmbeddings()\n",
        "client = chromadb.Client()\n",
        "# Local vector database containing document embeddings\n",
        "txt_docsearch = Chroma.from_documents(documents=txt_docs, embedding=embeddings)\n",
        "#logfile = \"output.log\"\n",
        "\n",
        "handler = StreamingStdOutCallbackHandler()\n",
        "\n",
        "# Define LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.6) # \"gpt-4\"\n",
        "\n",
        "# Create Retriever\n",
        "qa_txt = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", callbacks=[handler], retriever=txt_docsearch.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BsG5Oz0rpxy",
        "outputId": "60e2b70b-f063-4043-fb35-3bbadfd89f9a"
      },
      "outputs": [],
      "source": [
        "# q = 'Empty query here'  \n",
        "qa_txt.invoke(q)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E8sbYA1UZ8f_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
